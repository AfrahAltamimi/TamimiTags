{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#كود تجهيز مدونة الدراسة للتقطيع\n",
    "from lazyme import per_section\n",
    "import nltk \n",
    "training_sentences = [[tuple(token.split('\\t')) for token in sent] for sent in per_section(open('C:\\\\Test\\\\Seg\\\\TRAIN1.txt'))]\n",
    "test_sentences = [[tuple(token.split('\\t')) for token in sent] for sent in per_section(open('C:\\\\Test\\\\Seg\\\\TEST1.txt'))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#كود تجهيز مدونة الدراسة للتوسيم\n",
    "from lazyme import per_section\n",
    "import nltk \n",
    "training_sentences = [[tuple(token.split('\\t')) for token in sent] for sent in per_section(open('C:\\\\Test\\\\Training\\\\L1\\\\Train_L1.txt'))]\n",
    "test_sentences = [[tuple(token.split('\\t')) for token in sent] for sent in per_section(open('C:\\\\Test\\\\Testing\\\\L1\\\\Test_L1.txt'))]\n",
    "print(len(training_sentences))\n",
    "print(len(test_sentences))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# كود خصائص الحالة للتقطيع\n",
    "def features(sentence, index):\n",
    "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'prev_word1': '<s>' if index == 0 else sentence[index - 1],\n",
    "        'prev_word2': '<s>' if index == 0 else '<s>' if index == 1 else sentence[index - 2],\n",
    "        'next_word1': '/<s>' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'next_word2': '/<s>' if index == len(sentence) - 1 else '/<s>' if index == len(sentence) - 2 else sentence[index + 2],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# كود خصائص الحالة للتوسيم\n",
    "def features(sentence, index):\n",
    "    \"\"\" sentence: [w1, w2, ...], index: the index of the word \"\"\"\n",
    "    return {\n",
    "        'word': sentence[index],\n",
    "        'is_first': index == 0,\n",
    "        'is_last': index == len(sentence) - 1,\n",
    "        'prefix-1': sentence[index][0],\n",
    "        'prefix-2': sentence[index][:2],\n",
    "        'prefix-3': sentence[index][:3],\n",
    "        'prefix-4': sentence[index][:4],\n",
    "        'suffix-1': sentence[index][-1],\n",
    "        'suffix-2': sentence[index][-2:],\n",
    "        'suffix-3': sentence[index][-3:],\n",
    "        'prev_word1': '' if index == 0 else sentence[index - 1],  \n",
    "        'next_word1': '' if index == len(sentence) - 1 else sentence[index + 1],\n",
    "        'is_numeric': sentence[index].isdigit(),\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# كود نقل بيانات التدريب والاختبار لمجموعة بيانات dataset\n",
    "from nltk.tag.util import untag\n",
    "def transform_to_dataset(tagged_sentences):\n",
    "    X, y = [], []\n",
    "     for tagged in tagged_sentences:\n",
    "        X.append([features(untag(tagged), index) for index in range(len(tagged))])\n",
    "        y.append([tag for _, tag in tagged])\n",
    "    return X, y \n",
    "X_train, y_train = transform_to_dataset(training_sentences)\n",
    "X_test, y_test = transform_to_dataset(test_sentences) print(len(X_train))     \n",
    "print(len(X_test))         \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# كود تدريب نموذج CRFللتقطيع والتوسيم\n",
    "from sklearn_crfsuite import CRF\n",
    "import sklearn_crfsuite\n",
    "from sklearn_crfsuite import scorers\n",
    "from sklearn_crfsuite import metrics\n",
    "crf = sklearn_crfsuite.CRF(algorithm='lbfgs',\n",
    "    c1=0.01,\n",
    "    c2=0.01,\n",
    "    max_iterations=100000,\n",
    "    all_possible_transitions=True)\n",
    "crf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#كود اختبار نموذج CRFللتقطيع والتوسيم\n",
    "from sklearn_crfsuite import metrics\n",
    "y_pred = crf.predict(X_test)\n",
    "print(\"Accuracy = \",metrics.flat_accuracy_score(y_test, y_pred))\n",
    "print (\"Recall =\", metrics.flat_recall_score(y_test, y_pred, average='weighted',  labels=labels))\n",
    "print (\"Precision =\", metrics.flat_precision_score(y_test, y_pred, average='weighted',  labels=labels))\n",
    "print (\"F1 =\", metrics.flat_f1_score(y_test, y_pred, average='weighted',  labels=labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
